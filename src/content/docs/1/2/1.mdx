---
title: 1.2.1. 자막 제공
description: 멀티미디어 콘텐츠에는 자막, 대본 또는 수어를 제공해야 한다.
outline: { label:false }
lastUpdated: 2025-03-31
draft: false
---
import { Aside, Badge, Card } from '@astrojs/starlight/components';

<Aside title="검사 항목">
멀티미디어 콘텐츠에는 자막, 대본 또는 수어를 제공해야 한다.
</Aside>

## 목적
멀티미디어 콘텐츠가 전달하는 모든 정보(대화, 음향 효과, 배경 소리 등)가 청각이나 시각 등 특정 감각에 제한이 있는 사용자에게도 동등하게 전달되도록 자막, 대본 또는 수어와 같은 동등한 대체 수단을 제공하는 것이다.

##	배경 및 필요성
청각에 제한이 있는 사용자는 멀티미디어 콘텐츠에 포함된 소리를 제대로 듣지 못하거나 전혀 들을 수 없으므로, 자막, 대본, 또는 수어와 같은 대체 수단을 제공하여 다른 감각을 통해 정보를 인식할 수 있도록 지원해야 한다.

자막과 대본은 콘텐츠의 오디오 트랙과 동기화되어야 하며, 대화뿐만 아니라 음향 효과, 음악 등 비언어적 소리 정보도 함께 전달해야 한다. 이를 통해 모든 사용자가 콘텐츠의 의미와 맥락을 온전히 이해할 수 있으며, 특히 청각 장애가 있는 사용자도 정보 접근에서 배제되지 않는다.

또한, 시각에 제약이 있는 사용자는 영상 내 문자 정보나 나레이션이 없는 안내 동영상을 인식하기 어려울 수 있다. 따라서 청각을 활용하거나, 대본 등 다른 감각을 통해 콘텐츠를 이해할 수 있도록 제공해야 한다.

##	기본 규칙
다음 중 한 가지 이상의 대체 수단을 제공한다.

### 자막 제공
- 멀티미디어 콘텐츠의 오디오 정보를 화면에 자막으로 제공한다.
- 자막은 대화, 화자 식별, 음향 효과 등 모든 청각적 요소를 포함하며, 콘텐츠와 동기화되어야 한다.
- 자막 제공 방식은 열린 자막(Open Caption)과 닫힌 자막(Closed Caption)으로 구분된다. 사용자가 필요에 따라 자막을 켜거나 끌 수 있으며, 자막의 위치, 크기, 색상 등을 조정할 수 있는 닫힌 자막 방식을 제공하는 것이 더 유용하다.
- 소프트웨어 등에 의해 자동으로 생성된 자막은 정확도가 낮을 수 있으며, 중요한 배경 소리나 음악 등이 누락되거나 부정확하게 표현될 우려가 있다. 따라서 검토 및 보정 과정을 거쳐 제공해야 한다.

### 대본 제공
- 멀티미디어 콘텐츠의 오디오 및 비디오 트랙에서 전달되는 모든 정보를 문자로 변환한 대본을 제공한다.
- 대본은 대화뿐만 아니라 설명, 배경 소리, 음악 등 모든 청각적 요소가 포함되어야 한다.
- 대본은 사용자가 쉽게 확인할 수 있도록 멀티미디어 콘텐츠 근처에 배치하며, 현재 재생 중인 부분을 식별할 수 있도록 표시해야 한다.
- 내용이 길 경우, 화면 이동 없이 계속 확인할 수 있도록 스크롤 가능한 형태로 제공하며, 재생 중인 위치가 화면 내에서 유지되도록 자동 스크롤 기능을 지원하는 것이 바람직하다.

### 수어 제공
- 청각장애인 사용자가 멀티미디어 콘텐츠의 내용을 이해할 수 있도록, 수어를 통해 정보를 전달한다. 수어는 청각 장애인 사용자들에게 가장 익숙하고 자연스러운 언어이므로, 복잡하거나 전문적인 정보가 포함된 콘텐츠에서 특히 효과적이다.
- 콘텐츠 화면 내에서 수어 통역사가 명확히 보이도록 별도의 공간을 배치한다.
- 수어 화면은 콘텐츠의 주요 장면이나 텍스트를 가리지 않도록 배치하여 중요한 정보가 손실되지 않도록 해야 한다.

소리 없이 영상만 제공되는 콘텐츠에도 동일한 대체 수단이 필요하다.

시각에 제약이 있는 사용자는 멀티미디어 콘텐츠에 포함된 문자 정보나 영상을 인식하기 어려우므로, 청각 등 다른 감각을 활용할 수 있는 대체 정보를 제공해야 한다

### 대본 제공
- 청각을 사용하는데 제한이 있는 사용자를 위한 대본과 마찬가지로, 문자로 변환된 대본은 화면낭독프로그램을 통해 접근할 수 있어야 한다.
- 시각적 요소가 중요한 경우 해당 장면에 대한 설명도 포함하여, 사용자가 콘텐츠의 전체적인 맥락을 이해할 수 있도록 돕는다.

### (권고) 나레이션 또는 화면 해설 제공
- 시각적 정보를 인지하기 어려운 사용자를 위해, 멀티미디어 콘텐츠의 시각적 정보를 음성으로 설명하는 나레이션 또는 화면 해설을 제공한다.
- 화면 해설은 영상에서 전달하고자 하는 주요 시각적 정보를 설명해야 하며, 등장인물의 행동, 표정, 의상, 장면의 변화 등 대사만으로 이해하기 어려운 요소를 포함해야 한다.
- 원래의 음향을 방해하지 않도록, 대사나 중요한 음향 효과가 없는 부분에 삽입해야 한다.
- 콘텐츠의 시각적 정보와 동기화되도록 적절한 타이밍으로 제공해야 한다.
- 화면 해설을 제공하는 방식으로는 기본 음성 트랙에 화면 해설을 포함하는 통합 방식과 별도의 음성 트랙으로 제공하는 선택적 방식이 있다. 사용자가 필요에 따라 화면 해설을 켜고 끌 수 있는 선택적 방식을 권장한다.

## 용어
<dl>
	<dt>멀티미디어 콘텐츠</dt>
	<dd>오디오, 비디오, 이미지 등 여러 미디어 요소를 동기화하여 제공함으로써, 시간에 따라 변화하는 정보를 전달하는 콘텐츠를 의미한다. 이러한 콘텐츠에는 동영상이나 오디오와 같은 시간 기반 미디어가 포함되며, 재생 중 특정 시점에서 사용자의 상호작용(예: 재생, 일시정지, 특정 지점 이동)이 요구될 수 있다.</dd>
	<dt>오디오트랙(audiotrack)</dt>
	<dd>멀티미디어 콘텐츠에서 소리를 담고 있는 독립적인 부분을 의미한다. 음성, 음악, 효과음 등이 포함되며, 하나의 멀티미디어 콘텐츠에 여러 개의 오디오 트랙을 포함할 수 있다.</dd>
	<dt>동기화(synchronized)</dt>
	<dd>멀티미디어 콘텐츠에서 서로 다른 유형의 미디어 요소(예: 오디오, 비디오, 자막 등)가 시간적으로 일치하도록 조정되는 것을 의미한다. 예를 들어, 영화에서 배우의 대사(오디오)와 입술 움직임(비디오)이 정확히 맞아떨어지는 것이 동기화의 한 예이다.</dd>
	<dt>개방 자막 또는 열린 자막(Open Caption)</dt>
	<dd>영상에 고정되어 인코딩된 자막으로, 재생 시 항상 표시되는 자막을 의미한다. 이는 영상의 한 부분으로 포함되어 있어, 사용자가 자막을 켜거나 끌 수 없고, 개별적으로 조정할 수도 없다.</dd>
	<dt>폐쇄 자막 또는 닫힌 자막(Closed Caption)</dt>
	<dd>영상과 별도로 제공되어 사용자가 필요에 따라 켜거나 끌 수 있는 자막을 말한다. 자막 데이터가 영상과 분리되어 있어, 플레이어나 시스템 기능에 따라 자막의 위치, 크기, 글꼴, 색상 등을 사용자가 자유롭게 조정할 수 있다.</dd>
	<dt>화면 해설</dt>
	<dd>시각적 정보를 보조하는 별도의 음성 설명으로, 대사나 소리만으로 이해하기 어려운 장면(등장인물의 행동, 표정, 의상, 장면 변화 등)을 설명하는 기능을 한다. 이는 기존 대사나 중요한 소리를 방해하지 않는 구간에 제공된다.</dd>
</dl>

## 적용 사례

### 1)	멀티미디어 콘텐츠 정보의 동등한 자막 제공
멀티미디어 콘텐츠 내 대화, 의미 있는 음향 효과를 포함하여 소리를 통해 전달되는 비언어적 정보 등을 동등하게 이해할 수 있도록 자막을 제공한다.

이때, 자막은 실시간으로 내용을 파악할 수 있도록 동기화되며, 영상과 시각적으로 명확히 구분되도록 제공해야 한다. 대화가 포함된 경우, 화자의 식별 정보(예: “길동: 안녕하세요”)를 제공하여, 여러 사람이 대화하는 상황에서도 각 화자의 발언을 명확히 구분할 수 있도록 한다.
#### a)	말하는 사람을 식별할 수 있고 실시간으로 동기화된 대화 제공
여러 사람이 대화하는 상황에서 말하는 사람이 화면에 나타나지 않거나 여러 사람이 동시에 등장하는 경우, 대화 내용의 주체를 알기 어렵다.

이때, 말하는 사람을 함께 표시하여 자막을 제공하면, 사용자가 대화 내용을 더욱 정확하게 이해할 수 있다.

<figure>
	![](/images/121/01.png)
	<figcaption>이미지. 자막에 화자가 함께 표시된 사례 (출처: 넷플릭스 - 드라마 연인)</figcaption>
</figure>

#### b)	의미 있는 음향 효과 제공
예를 들어, 범인을 따돌리기 위해 가속하는 자동차의 엔진 소리가 강조된 장면에서, 소리를 들을 수 없는 사용자는 해당 장면의 긴박감이나 의도를 제대로 인식하지 못할 수 있다.

이때, 자막에 의미 있는 음향 효과를 추가로 제공하면, 사용자가 장면이 전달하고자 하는 맥락과 상황을 더욱 명확히 이해할 수 있다.

<figure>
	![](/images/121/02.png)
	<figcaption>이미지. 자막에 음향 효과가 표시된 사례 (출처: Wavve - 드라마 모범택시)</figcaption>
</figure>

### 2)	멀티미디어 콘텐츠 정보를 동등하게 이해할 수 있는 대본 제공
멀티미디어 콘텐츠 내 대화, 의미 있는 음향 효과, 비언어적 소리 정보 등을 동등하게 이해할 수 있도록 대본을 제공한다. 이때, 대본은 영상과 함께 볼 수 있는 위치에 배치되어야 한다.
다음은 영상과 동시에 볼 수 있으며 자동으로 스크롤 되는 대본이 제공된 사례이다.

<figure>
	![](/images/121/03.jpg)
	<figcaption>이미지. 영상과 함께 볼 수 있도록 대본이 배치 된 사례 (출처: 유튜브 - 한수원)</figcaption>
</figure>

### 3)	멀티미디어 콘텐츠 정보를 동등하게 이해할 수 있는 수어 제공
멀티미디어 콘텐츠 내 대화, 의미 있는 음향 효과를 포함하여 소리를 통해 전달되는 비언어적 정보 등을 동등하게 이해할 수 있는 수어를 제공한다. 

이때, 자막과 함께 제공되는 수어 영상일 경우, 자막과 영상이 겹치지 않아야 한다. 또한, 수어 통역사가 함께 촬영된 콘텐츠의 경우, 화면 각도나 거리와 관계없이 수어가 명확히 보이도록 제공해야 한다.

#### a)	실시간 수어 제공

<figure>
	![](/images/121/04.png)
	<figcaption>이미지. 영상과 별도의 수어 영상이 함께 제공되는 사례 (출처: 유튜브 - KBS뉴스)</figcaption>
</figure>

#### b)	실시간 수어 제공
<figure>
	![](/images/121/05.png)
	<figcaption>이미지. 수어 통역사가 함께 등장하는 영상 사례 (출처: 유튜브 - KBS 뉴스)</figcaption>
</figure>

#### c)	자막과 수어 제공
<figure>
	![](/images/121/06.png)
	<figcaption>이미지. 자막과 수어 영상이 함께 제공된 영상 사례 (출처: 유튜브 - KBS뉴스)</figcaption>
</figure>

### 4)	(권고) 화면 해설 콘텐츠 제공
소리 없이 등장인물의 행동이나 표정만 보여지는 경우, 동작이나 과정을 화면으로만 표현하는 경우, 혹은 소리만으로 상황을 이해하기 어려운 경우에는 장면의 상황을 설명하는 음성 정보를 추가 제공해야 한다.

#### a)	화면 해설 전용 콘텐츠 제공
청각적으로 정보를 얻는 사용자가 장면의 시각적 맥락과 의도를 더 깊이 이해할 수 있도록 화면 해설 전용 콘텐츠를 제공할 수 있다.

<figure>
	![](/images/121/07.png)
	<figcaption>이미지. 화면 해설 전용 콘텐츠를 제공한 사례 (출처: Wavve)</figcaption>
</figure>

#### b)	화면 해설을 별도의 오디오 트랙으로 제공
화면 해설이 없는 기본 트랙과 화면 해설이 포함된 트랙을 분리하여 제공하면, 다양한 사용자 경험을 제공할 수 있다. 이를 통해 사용자는 필요에 따라 화면 해설을 켜거나 끌 수 있다.

<figure>
	![](/images/121/08.png)
	<figcaption>이미지. 화면 해설 설정이 제공된 멀티미디어 콘텐츠 사례 (출처: 넷플릭스 - 오징어게임)</figcaption>
</figure>

## 개선 필요 사례
### 1)	멀티미디어 콘텐츠 내 소리를 통해 전달되는 정보의 대체 수단 미제공
의학 정보를 전달하는 영상에서 갑상선암의 진단과 치료 방법을 음성으로만 제공하는 사례이다. 소리로만 제공되기 때문에, 소리를 듣는 데 제약이 있는 사용자는 해당 정보를 알기 어렵다.

<figure>
	![](/images/121/09.png)
	<figcaption>이미지. 동영상 내용이 음성으로만 제공되는 영상 사례</figcaption>
</figure>

#### 개선 방법
소리 외에 자막, 대본 또는 수어를 제공하여 다른 감각을 통해 정보를 전달할 수 있도록 한다.

### 2)	자막과 수어가 서로 겹쳐져 제공
자막과 수어 영상이 겹쳐서 제공되는 사례로, 자막 일부가 가려져 내용을 확인하기 어려운 문제가 발생한다.

<figure>
	![](/images/121/10.png)
	<figcaption>이미지. 진행자의 대사 자막과 수어 영상이 겹쳐 표시된 영상 사례</figcaption>
</figure>

#### 개선 방법
자막과 수어 영상이 겹쳐지지 않도록 배치하거나, 사용자가 자막이나 수어를 선택하여 볼 수 있는 기능을 제공한다.

### 3)	수어 통역사의 통역하는 모습을 확인 불가
행사를 실시간으로 중계하는 영상에서, 촬영 위치나 거리, 화면 전환 등으로 인해 수어 통역사가 일시적으로 보이지 않게 되는 사례이다. 이로 인해 소리를 듣기 어려운 사용자는 수어 통역이 제공되고 있음에도 행사 내용을 이해하기 어렵다.

<figure>
	![](/images/121/11.png)
	<figcaption>이미지. 먼 거리에서 촬영되어 수어 통역사가 거의 보이지 않는 사례</figcaption>
</figure>

<figure>
	![](/images/121/12.png)
	<figcaption>이미지. 발표자에 가려져 수어 통역사가 보이지 않는 사례</figcaption>
</figure>

#### 개선 방법
수어 통역사가 통역하는 영상을 화면에 별도로 제공하거나, 수어 통역사가 정면에서 항상 보이도록 화면을 구성한다.

### 4)	말하는 사람이 식별되지 않은 자막 제공
화면 밖에서 말하는 사람이 있는 경우, 자막에 화자 정보가 포함되지 않아 누가 말하는지 알기 어려운 사례이다. 이로 인해 소리를 듣기 어려운 사용자가 콘텐츠 내용이나 맥락을 잘못 이해할 수 있다.

<figure>
	![](/images/121/13.png)
	<figcaption>이미지. 화면 밖 여러 인물들의 말이 자막으로 제공되는 사례</figcaption>
</figure>

#### 개선 방법
자막에 화자를 표시하여, 사용자가 콘텐츠의 내용과 맥락을 이해할 수 있도록 한다.

<figure>
	![](/images/121/14.jpg)
	<figcaption>이미지. 화자 이름이 같이 표기된 자막 제공 사례</figcaption>
</figure>

